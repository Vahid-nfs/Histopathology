import osimport numpy as npimport pandas as pdimport cv2import matplotlib.pyplot as pltfrom sklearn.model_selection import train_test_splitfrom sklearn.metrics import classification_reportfrom sklearn.metrics import confusion_matrix ,plot_confusion_matriximport seaborn as snsimport torch import torch.nn as nnimport torch.nn.functional as Fimport torchvision.transforms as transformsfrom torch.utils.data import TensorDataset, DataLoader, Datasetimport torch_optimizer as optimfrom glob import globimagePatches = glob('./data/IDC_regular_ps50_idx5/**/*.png', recursive=True)try:    os.makedirs("./checkpoint")except :    pass      images_df = pd.DataFrame(imagePatches,columns=["images"])images_df["labels"]=images_df["images"].apply(lambda x: int(x.rsplit(".")[-2][-1]))    print(images_df.head())print(images_df.value_counts("labels"))# Shuffle image_dfimages_df=images_df.sample(frac=1,ignore_index=True)# Train test splittrain, val = train_test_split(images_df, stratify=images_df.labels, test_size=0.2)len(train), len(val)# Create dataset classclass MyDataset(Dataset):    def __init__(self, df_data,transform=None):        super().__init__()        self.df = df_data.values                self.transform = transform    def __len__(self):        return len(self.df)        def __getitem__(self, index):        img_path,label = self.df[index]                image = cv2.imread(img_path)        image = cv2.resize(image, (50,50))        x = cv2.Sobel(image, cv2.CV_16S, 1, 0) # Yes x Find the first derivative         y = cv2.Sobel(image, cv2.CV_16S, 0, 1) # Yes y Find the first derivative         absX = cv2.convertScaleAbs(x)        absY = cv2.convertScaleAbs(y)        image = cv2.addWeighted(absX, 0.5, absY, 0.5, 0)                if self.transform is not None:            image = self.transform(image)        return image, label        ## Parameters for model# Hyper parametersnum_epochs = 10num_classes = 2batch_size = 8*16learning_rate = 0.002# Device configurationdevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')# Define transformstrans_train = transforms.Compose([transforms.ToPILImage(),                                   transforms.Pad(64, padding_mode='reflect'),                                   transforms.RandomHorizontalFlip(),                                    transforms.RandomVerticalFlip(),                                   transforms.RandomRotation(20),                                   transforms.ToTensor(),                                   transforms.Normalize(mean=[0.5, 0.5, 0.5],std=[0.5, 0.5, 0.5])                                  ])trans_valid = transforms.Compose([transforms.ToPILImage(),                                   transforms.Pad(64, padding_mode='reflect'),                                  transforms.ToTensor(),                                   transforms.Normalize(mean=[0.5, 0.5, 0.5],std=[0.5, 0.5, 0.5])                                  ])# Create datasetdataset_train = MyDataset(df_data=train, transform=trans_train)dataset_valid = MyDataset(df_data=val,transform=trans_valid)# Create dataloaderloader_train = DataLoader(dataset = dataset_train, batch_size=batch_size, shuffle=True, num_workers=0)loader_valid = DataLoader(dataset = dataset_valid, batch_size=batch_size//2, shuffle=False, num_workers=0)            class CNN(nn.Module):    def __init__(self):        super(CNN, self).__init__()                self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=2)        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=2)        self.conv23=nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=2)        self.conv34=nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=2)        self.conv45=nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)        self.conv5 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=2)        self.bn1 = nn.BatchNorm2d(32)        self.bn2 = nn.BatchNorm2d(64)        self.bn3 = nn.BatchNorm2d(128)        self.bn4 = nn.BatchNorm2d(256)        self.bn5 = nn.BatchNorm2d(512)        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)        self.avg = nn.AvgPool2d(7)        self.fc = nn.Linear(512 * 1 * 1, 2) # !!!            def forward(self, x):        lenX=len(x)        x = self.pool(F.leaky_relu(self.bn1(self.conv1(x))))                 lst=[]        x = self.pool(F.leaky_relu(self.bn2(self.conv2(x))))        for i in range(0,lenX,8):            dx= F.leaky_relu(self.bn2(self.conv23(x[i:i+8])))            lst.append(dx)        dx=torch.cat(lst)        x=x+dx                lst=[]        x = self.pool(F.leaky_relu(self.bn3(self.conv3(x))))        for i in range(0,lenX,8):            dx= F.leaky_relu(self.bn3(self.conv34(x[i:i+8])))            lst.append(dx)        dx=torch.cat(lst)        x=x+dx                lst=[]        x = self.pool(F.leaky_relu(self.bn4(self.conv4(x))))        for i in range(0,lenX,8):            dx= F.leaky_relu(self.bn4(self.conv45(x[i:i+8])))            lst.append(dx)        dx=torch.cat(lst)        x=x+dx                x = self.pool(F.leaky_relu(self.bn5(self.conv5(x))))        x = self.avg(x)        x = x.view(-1, 512 * 1 * 1) # !!!        x = self.fc(x)        return x    # Create model objectmodel = CNN().to(device)# Print model architecturefrom torchsummary import summarysummary(model,(3, 178, 178))# Loss and optimizercriterion = nn.CrossEntropyLoss()# optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)optimizer = optim.AdaBound(    model.parameters(),    lr= 1e-3,    betas= (0.9, 0.999),    final_lr = 0.1,    gamma=1e-3,    eps= 1e-8,    weight_decay=0,    amsbound=False,)total_step = len(loader_train)for epoch in range(num_epochs):    for i, (images, labels) in enumerate(loader_train):        images = images.to(device)        labels = labels.to(device)                # Forward pass        outputs = model(images)        loss = criterion(outputs, labels)                # Backward and optimize        optimizer.zero_grad()        loss.backward()        optimizer.step()        _, pred = torch.max(outputs.data, 1)        correct = (pred == labels).sum().item()        acc=100*(correct/len(images))                                if (i+1) % 1 == 0:            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f} , accuracy: {:.2f}'                     .format(epoch+1, num_epochs, i+1, total_step, loss.item(),acc))            print(confusion_matrix(labels,pred))    torch.save(model, f'./checkpoint/model{epoch+1}.pth')total_lbl=[]total_pred=[]with torch.no_grad():    correct = 0    total = 0    for images, labels in loader_valid:        images = images.to(device)        labels = labels.to(device)        outputs = model(images)        _, predicted = torch.max(outputs.data, 1)        total += labels.size(0)        correct += (predicted == labels).sum().item()        total_lbl+=list(labels)        total_pred+=list(predicted)                     print('Test Accuracy of the model on the test images: {} %'.format(100 * correct / total))# Save the model checkpointtorch.save(model.state_dict(), 'model.ckpt')print(classification_report(total_lbl,total_pred,target_names=["IDC negative","IDC posetive"]))plt.figure(figsize = (9,7))sns.heatmap(confusion_matrix(total_lbl,total_pred),            yticklabels=["IDC negative","IDC posetive"],            xticklabels=["IDC negative","IDC posetive"],             annot=True, fmt='d')plt.xlabel('Predicted')plt.ylabel('Truth')    